hjson
ninja
numpy
packaging
psutil
py-cpuinfo
pydantic
torch
tqdm

[1bit]
cupy-cuda116

[1bit_mpi]
mpi4py
cupy-cuda116

[all]
tensorboard
hjson
pydantic
pytest-randomly
torch
pytest-forked
triton==2.0.0.dev20221005
clang-format>=14.0.6
mpi4py
pytest
triton==1.0.0
recommonmark
tqdm
megatron-lm==1.1.5
docutils<0.18
future
transformers[sentencepiece]
google
torchvision
cupy-cuda116
pre-commit>=2.20.0
diffusers
packaging
transformers
xgboost
importlib-metadata>=4
pytest-xdist
sphinx
tabulate
psutil
lm-eval>=0.2.0
protobuf
py-cpuinfo
wandb
sphinx-rtd-theme

[autotuning]
tabulate

[autotuning_ml]
hjson
tabulate
xgboost

[dev]
clang-format>=14.0.6
docutils<0.18
future
importlib-metadata>=4
megatron-lm==1.1.5
pre-commit>=2.20.0
pytest
pytest-forked
pytest-randomly
pytest-xdist
recommonmark
sphinx
sphinx-rtd-theme
tensorboard
torchvision
transformers
wandb

[inf]
google
lm-eval>=0.2.0
protobuf
transformers
transformers[sentencepiece]

[readthedocs]
docutils<0.18
hjson
packaging
psutil
py-cpuinfo
pydantic
torch
tqdm

[sd]
diffusers
triton==2.0.0.dev20221005

[sparse_attn]
triton==1.0.0
