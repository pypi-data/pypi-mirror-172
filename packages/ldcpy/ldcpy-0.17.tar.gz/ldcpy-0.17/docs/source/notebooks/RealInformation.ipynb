{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f91f2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Missing module name.\n"
     ]
    }
   ],
   "source": [
    "# Add ldcpy root to system path\n",
    "import struct\n",
    "import sys\n",
    "from math import log2\n",
    "\n",
    "import astropy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "# Import ldcpy package\n",
    "# Autoreloads package everytime the package is called, so changes to code will be reflected in the notebook if the above sys.path.insert(...) line is uncommented.\n",
    "%load_ext\n",
    "%autoreload 2\n",
    "\n",
    "# suppress all of the divide by zero warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import ldcpy\n",
    "\n",
    "# display the plots in this notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf35fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HDF5_PLUGIN_PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeeabbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_ts is a collection containing TS data\n",
    "col_ts = ldcpy.open_datasets(\n",
    "    \"cam-fv\",\n",
    "    [\"TS\"],\n",
    "    [\n",
    "        \"../../../data/cam-fv/orig.TS.100days.nc\",\n",
    "        \"../../../data/cam-fv/zfp1e-1.TS.100days.nc\",\n",
    "        \"../../../data/cam-fv/zfp1.0.TS.100days.nc\",\n",
    "    ],\n",
    "    [\"orig\", \"zfpA1e-1\", \"zfpA1.0\"],\n",
    ")\n",
    "# col_prect contains PRECT data\n",
    "col_prect = ldcpy.open_datasets(\n",
    "    \"cam-fv\",\n",
    "    [\"PRECT\"],\n",
    "    [\n",
    "        \"../../../data/cam-fv/orig.PRECT.60days.nc\",\n",
    "        \"../../../data/cam-fv/zfp1e-11.PRECT.60days.nc\",\n",
    "        \"../../../data/cam-fv/zfp1e-7.PRECT.60days.nc\",\n",
    "    ],\n",
    "    [\"orig\", \"zfpA1e-11\", \"zfpA1e-7\"],\n",
    ")\n",
    "\n",
    "ts_array = np.array(col_ts[\"TS\"].isel(time=0).values)\n",
    "prect_array = np.array(col_prect[\"PRECT\"].isel(time=0).values)\n",
    "\n",
    "\n",
    "# See here for a list of variables with more information:\n",
    "# https://www.cesm.ucar.edu/projects/community-projects/LENS/data-sets.html\n",
    "\n",
    "daily_variables = [\"TS\", \"FLNS\", \"ICEFRAC\", \"PRECT\", \"PSL\", \"Q200\", \"TAUX\", \"WSPDSRFAV\", \"Z500\"]\n",
    "data_path = \"/glade/p/cisl/asap/CAM_lossy_test_data_31/research\"\n",
    "\n",
    "cols_daily = {}\n",
    "sets = {}\n",
    "levels = {}\n",
    "climate_var_arrays = {}\n",
    "\n",
    "compression_levels = [24, 22, 20, 18, 16, 14, 12, 10, 8]\n",
    "\n",
    "for variable in daily_variables:\n",
    "    print(variable)\n",
    "\n",
    "    new_levels = [f\"orig_{variable}\"]\n",
    "    new_sets = [\n",
    "        f\"{data_path}/daily_orig/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\"\n",
    "    ]\n",
    "\n",
    "    for value in compression_levels:\n",
    "        new_level = f\"zfp_p_{value}_{variable}\"\n",
    "        new_set = f\"{data_path}/daily_zfp_hdf5/zfp_p_{value}/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\"\n",
    "\n",
    "        new_levels.append(new_level)\n",
    "        new_sets.append(new_set)\n",
    "\n",
    "    levels[variable] = new_levels\n",
    "    sets[variable] = new_sets\n",
    "\n",
    "    cols_daily[variable] = ldcpy.open_datasets(\n",
    "        \"cam-fv\", [f\"{variable}\"], sets[variable], levels[variable], chunks={\"time\": 700}\n",
    "    )\n",
    "    climate_var_arrays[variable] = np.array(cols_daily[variable][variable].isel(time=0).values)\n",
    "\n",
    "# array indexing example\n",
    "# climate_var_arrays[\"TS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5665e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary(num):\n",
    "    return ''.join(f'{c:0>8b}' for c in struct.pack('!f', num))\n",
    "\n",
    "\n",
    "# NOTE: They only look backward\n",
    "def get_prev_bit(bit_pos):\n",
    "    return [bit_pos[0] - 1, bit_pos[1]]\n",
    "\n",
    "\n",
    "N_BITS = 32\n",
    "\n",
    "\n",
    "def getbpe(data_array, x_index, title):\n",
    "    dict_list_H = []\n",
    "    for i in range(N_BITS - 1):\n",
    "        new_dict = {\"00\": 0, \"01\": 0, \"10\": 0, \"11\": 0}\n",
    "        dict_list_H.append(new_dict)\n",
    "\n",
    "    num_measurements = 0\n",
    "    for y in range(1, data_array.shape[1]):\n",
    "        for z in range(data_array.shape[2]):\n",
    "            num_measurements += 1\n",
    "\n",
    "            bit_pos = [y, z]\n",
    "            current_data = data_array[x_index][y][z]\n",
    "            current_data = binary(current_data)\n",
    "\n",
    "            adj_data_index = get_prev_bit(bit_pos)\n",
    "            y_adj, z_adj = adj_data_index\n",
    "            adj_data = data_array[x_index][y_adj][z_adj]\n",
    "            adj_data = binary(adj_data)\n",
    "\n",
    "            for i in range(N_BITS - 1):\n",
    "                current_bit = int(current_data[i])\n",
    "                adjacent_bit = int(adj_data[i])\n",
    "\n",
    "                p00 = p01 = p10 = p11 = 0\n",
    "                if current_bit == 0 and adjacent_bit == 0:\n",
    "                    p00 = 1\n",
    "                elif current_bit == 0 and adjacent_bit == 1:\n",
    "                    p01 = 1\n",
    "                elif current_bit == 1 and adjacent_bit == 0:\n",
    "                    p10 = 1\n",
    "                elif current_bit == 1 and adjacent_bit == 1:\n",
    "                    p11 = 1\n",
    "\n",
    "                dict_list_H[i][\"00\"] += p00\n",
    "                dict_list_H[i][\"01\"] += p01\n",
    "                dict_list_H[i][\"10\"] += p10\n",
    "                dict_list_H[i][\"11\"] += p11\n",
    "\n",
    "    bit_pos_H = []\n",
    "    Hs = []\n",
    "    diff = []\n",
    "    for bit_pos_dict in dict_list_H:\n",
    "        p00 = bit_pos_dict[\"00\"] / num_measurements\n",
    "        p01 = bit_pos_dict[\"01\"] / num_measurements\n",
    "        p10 = bit_pos_dict[\"10\"] / num_measurements\n",
    "        p11 = bit_pos_dict[\"11\"] / num_measurements\n",
    "\n",
    "        p0 = p00 + p01\n",
    "        p1 = p10 + p11\n",
    "\n",
    "        H = 0\n",
    "        if p0 != 0:\n",
    "            H -= p0 * log2(p0)\n",
    "        if p1 != 0:\n",
    "            H -= p1 * log2(p1)\n",
    "\n",
    "        Hs.append(H)\n",
    "\n",
    "        H0 = 0\n",
    "        if p00 != 0:\n",
    "            H0 += p00 * log2(p00)\n",
    "\n",
    "        if p01 != 0:\n",
    "            H0 += p01 * log2(p01)\n",
    "\n",
    "        H1 = 0\n",
    "        if p10 != 0:\n",
    "            H1 += p10 * log2(p10)\n",
    "\n",
    "        if p11 != 0:\n",
    "            H1 += p11 * log2(p11)\n",
    "\n",
    "        prob_H = -p0 * H0 - p1 * H1\n",
    "\n",
    "        bit_pos_H.append(prob_H)\n",
    "\n",
    "        diff.append(H - prob_H)\n",
    "\n",
    "    compression_levels = [24, 22, 20, 18, 16, 14, 12, 10, 8]\n",
    "    compression_levels = [\"ZFP_\" + str(x) for x in compression_levels]\n",
    "    compression_levels = [\"Orig\"] + compression_levels\n",
    "\n",
    "    # plt.plot(bit_pos_H)\n",
    "    # plt.plot(Hs)\n",
    "    plt.plot(diff)\n",
    "    plt.ylabel(\"Information content\")\n",
    "    plt.xlabel(\"Bit position\")\n",
    "    # plt.title(title + \" \" + compression_levels[x_index] + \" \" + str(sum(diff)))\n",
    "    # plt.legend([\"H\", \"Conditional H\", \"I(b)\"])\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "compression_levels = [24, 22, 20, 18, 16, 14, 12, 10, 8]\n",
    "compression_levels = [\"ZFP_\" + str(x) for x in compression_levels]\n",
    "compression_levels = [\"Orig\"] + compression_levels\n",
    "\n",
    "for daily_variable in daily_variables:\n",
    "    arr = climate_var_arrays[daily_variable]\n",
    "    for i in range(arr.shape[0]):\n",
    "        getbpe(arr, i, daily_variable)\n",
    "    plt.title(daily_variable)\n",
    "    plt.legend(compression_levels)\n",
    "    plt.show()\n",
    "    # print()\n",
    "    # print()\n",
    "    # print()\n",
    "    # print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
